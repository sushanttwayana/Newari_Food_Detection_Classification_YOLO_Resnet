{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages (9.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Processed 7545 images.\n",
      "Images are stored in 'final_splitted_dataset/images/' and XML files are organized by class inside 'final_splitted_dataset/xmls/'.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from PIL import Image\n",
    "# import shutil\n",
    "\n",
    "# # Define paths based on your structure\n",
    "# root_dir = \"final_splitted_dataset\"\n",
    "# train_dir = os.path.join(root_dir, \"train\")\n",
    "# test_dir = os.path.join(root_dir, \"test\")\n",
    "# output_images_dir = os.path.join(root_dir, \"images\")\n",
    "# output_xml_base_dir = os.path.join(root_dir, \"xmls\")  # Base XML directory\n",
    "\n",
    "# # Ensure output directories exist\n",
    "# os.makedirs(output_images_dir, exist_ok=True)\n",
    "# os.makedirs(output_xml_base_dir, exist_ok=True)\n",
    "\n",
    "# # Supported image formats (case-insensitive)\n",
    "# VALID_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"}\n",
    "\n",
    "# # Function to create Pascal VOC XML annotation\n",
    "# def create_voc_xml(image_path, class_name, output_xml_dir):\n",
    "#     try:\n",
    "#         image = Image.open(image_path)\n",
    "#         width, height = image.size\n",
    "#     except Exception as e:\n",
    "#         print(f\"Skipping {image_path} due to error: {e}\")\n",
    "#         return\n",
    "\n",
    "#     annotation = ET.Element(\"annotation\")\n",
    "\n",
    "#     folder = ET.SubElement(annotation, \"folder\")\n",
    "#     folder.text = \"images\"\n",
    "\n",
    "#     filename = ET.SubElement(annotation, \"filename\")\n",
    "#     filename.text = os.path.basename(image_path)\n",
    "\n",
    "#     size = ET.SubElement(annotation, \"size\")\n",
    "#     width_elem = ET.SubElement(size, \"width\")\n",
    "#     width_elem.text = str(width)\n",
    "#     height_elem = ET.SubElement(size, \"height\")\n",
    "#     height_elem.text = str(height)\n",
    "#     depth = ET.SubElement(size, \"depth\")\n",
    "#     depth.text = \"3\"  # Assuming RGB images\n",
    "\n",
    "#     obj = ET.SubElement(annotation, \"object\")\n",
    "#     name = ET.SubElement(obj, \"name\")\n",
    "#     name.text = class_name\n",
    "\n",
    "#     bndbox = ET.SubElement(obj, \"bndbox\")\n",
    "#     xmin = ET.SubElement(bndbox, \"xmin\")\n",
    "#     xmin.text = \"0\"\n",
    "#     ymin = ET.SubElement(bndbox, \"ymin\")\n",
    "#     ymin.text = \"0\"\n",
    "#     xmax = ET.SubElement(bndbox, \"xmax\")\n",
    "#     xmax.text = str(width)\n",
    "#     ymax = ET.SubElement(bndbox, \"ymax\")\n",
    "#     ymax.text = str(height)\n",
    "\n",
    "#     # Ensure class-specific XML folder exists\n",
    "#     class_xml_dir = os.path.join(output_xml_dir, class_name)\n",
    "#     os.makedirs(class_xml_dir, exist_ok=True)\n",
    "\n",
    "#     # Save XML inside the class-specific folder\n",
    "#     xml_filename = os.path.join(class_xml_dir, os.path.splitext(os.path.basename(image_path))[0] + \".xml\")\n",
    "#     tree = ET.ElementTree(annotation)\n",
    "#     tree.write(xml_filename)\n",
    "\n",
    "# # Count processed images\n",
    "# total_images = 0\n",
    "\n",
    "# # Process train and test folders\n",
    "# for dataset_type, dataset_path in [(\"train\", train_dir), (\"test\", test_dir)]:\n",
    "#     for class_name in os.listdir(dataset_path):\n",
    "#         class_path = os.path.join(dataset_path, class_name)\n",
    "#         if os.path.isdir(class_path):\n",
    "#             for img in os.listdir(class_path):\n",
    "#                 img_ext = os.path.splitext(img)[1].lower()\n",
    "#                 if img_ext in VALID_EXTENSIONS:\n",
    "#                     img_path = os.path.join(class_path, img)\n",
    "\n",
    "#                     # Create unique filenames to prevent overwriting\n",
    "#                     new_filename = f\"{dataset_type}_{class_name}_{img}\"\n",
    "#                     new_img_path = os.path.join(output_images_dir, new_filename)\n",
    "\n",
    "#                     try:\n",
    "#                         # Copy the image to \"images\" folder\n",
    "#                         shutil.copy(img_path, new_img_path)\n",
    "#                         create_voc_xml(new_img_path, class_name, output_xml_base_dir)\n",
    "#                         total_images += 1\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "# print(f\"Conversion complete! Processed {total_images} images.\")\n",
    "# print(\"Images are stored in 'final_splitted_dataset/images/' and XML files are organized by class inside 'final_splitted_dataset/xmls/'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pillow\n",
      "Version: 10.4.0\n",
      "Summary: Python Imaging Library (Fork)\n",
      "Home-page: https://python-pillow.org\n",
      "Author: \n",
      "Author-email: \"Jeffrey A. Clark\" <aclark@aclark.net>\n",
      "License: HPND\n",
      "Location: c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: bokeh, datashader, imageio, matplotlib, scikit-image, sentence-transformers, streamlit\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ./archive/NewaFoodDataset\\images\\aug_152_jpg.rf.f2c9f26723e85ed650dde7234cf4061c.jpg (no annotations found in ./archive/NewaFoodDataset\\labels\\aug_152_jpg.rf.f2c9f26723e85ed650dde7234cf4061c.txt)\n",
      "Skipping ./archive/NewaFoodDataset\\images\\aug_168_jpg.rf.b3a9438ba3e8fb39ef6ac7a761396cfa.jpg (no annotations found in ./archive/NewaFoodDataset\\labels\\aug_168_jpg.rf.b3a9438ba3e8fb39ef6ac7a761396cfa.txt)\n",
      "Skipping ./archive/NewaFoodDataset\\images\\aug_207_jpg.rf.87da9b8abdf464734ba9214b6030035a.jpg (no annotations found in ./archive/NewaFoodDataset\\labels\\aug_207_jpg.rf.87da9b8abdf464734ba9214b6030035a.txt)\n",
      "Skipping ./archive/NewaFoodDataset\\images\\aug_291_jpg.rf.e88e5987fdec7ed99901e563a912023d.jpg (no annotations found in ./archive/NewaFoodDataset\\labels\\aug_291_jpg.rf.e88e5987fdec7ed99901e563a912023d.txt)\n",
      "Skipping ./archive/NewaFoodDataset\\images\\aug_436_jpg.rf.d1177f9372b8540b86423c857689b930.jpg (no annotations found in ./archive/NewaFoodDataset\\labels\\aug_436_jpg.rf.d1177f9372b8540b86423c857689b930.txt)\n",
      "Skipping ./archive/NewaFoodDataset\\images\\aug_455_jpg.rf.f8723cdc030518fb66733c3093c48db7.jpg (no annotations found in ./archive/NewaFoodDataset\\labels\\aug_455_jpg.rf.f8723cdc030518fb66733c3093c48db7.txt)\n",
      "Skipping ./archive/NewaFoodDataset\\images\\aug_490_jpg.rf.c57babf646d87547f4a95f6771a64f6d.jpg (no annotations found in ./archive/NewaFoodDataset\\labels\\aug_490_jpg.rf.c57babf646d87547f4a95f6771a64f6d.txt)\n",
      "Skipping ./archive/NewaFoodDataset\\images\\aug_496_jpg.rf.3a1f5bd58da0bcbda7f36905ded5f395.jpg (no annotations found in ./archive/NewaFoodDataset\\labels\\aug_496_jpg.rf.3a1f5bd58da0bcbda7f36905ded5f395.txt)\n",
      "Skipping ./archive/NewaFoodDataset\\images\\aug_567_jpg.rf.e6516255f892e69ebf2047daa7241218.jpg (no annotations found in ./archive/NewaFoodDataset\\labels\\aug_567_jpg.rf.e6516255f892e69ebf2047daa7241218.txt)\n",
      "âœ… Conversion complete! Processed 7495 images.\n",
      "ðŸ“‚ XML annotations are stored inside 'final_splitted_dataset/xmls/'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "# Define dataset directories\n",
    "root_dir = \"./archive/NewaFoodDataset\"\n",
    "images_dir = os.path.join(root_dir, \"images\")\n",
    "txt_dir = os.path.join(root_dir, \"labels\")  # Assuming TXT annotations are inside \"labels\"\n",
    "xml_output_dir = os.path.join(root_dir, \"xmls\")  # Pascal VOC XML output folder\n",
    "\n",
    "# Ensure XML output directory exists\n",
    "os.makedirs(xml_output_dir, exist_ok=True)\n",
    "\n",
    "# Supported image formats\n",
    "VALID_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"}\n",
    "\n",
    "# Function to create Pascal VOC XML file\n",
    "def create_voc_xml(image_path, txt_path, class_dict, output_xml_dir):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        width, height = image.size\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {image_path} due to error: {e}\")\n",
    "        return\n",
    "\n",
    "    # Read the TXT file (assuming YOLO format: class_id cx cy w h)\n",
    "    with open(txt_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    if not lines:\n",
    "        print(f\"Skipping {image_path} (no annotations found in {txt_path})\")\n",
    "        return\n",
    "\n",
    "    annotation = ET.Element(\"annotation\")\n",
    "\n",
    "    folder = ET.SubElement(annotation, \"folder\")\n",
    "    folder.text = \"images\"\n",
    "\n",
    "    filename = ET.SubElement(annotation, \"filename\")\n",
    "    filename.text = os.path.basename(image_path)\n",
    "\n",
    "    size = ET.SubElement(annotation, \"size\")\n",
    "    width_elem = ET.SubElement(size, \"width\")\n",
    "    width_elem.text = str(width)\n",
    "    height_elem = ET.SubElement(size, \"height\")\n",
    "    height_elem.text = str(height)\n",
    "    depth = ET.SubElement(size, \"depth\")\n",
    "    depth.text = \"3\"  # Assuming RGB images\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            print(f\"Skipping malformed annotation in {txt_path}: {line}\")\n",
    "            continue\n",
    "\n",
    "        class_id, cx, cy, w, h = map(float, parts)\n",
    "        class_name = class_dict.get(int(class_id), f\"class_{int(class_id)}\")  # Map class ID to name\n",
    "\n",
    "        # Convert YOLO format (normalized) to Pascal VOC absolute values\n",
    "        xmin = int((cx - w / 2) * width)\n",
    "        ymin = int((cy - h / 2) * height)\n",
    "        xmax = int((cx + w / 2) * width)\n",
    "        ymax = int((cy + h / 2) * height)\n",
    "\n",
    "        # Ensure bounding box is within image dimensions\n",
    "        xmin, ymin, xmax, ymax = max(0, xmin), max(0, ymin), min(width, xmax), min(height, ymax)\n",
    "\n",
    "        obj = ET.SubElement(annotation, \"object\")\n",
    "        name = ET.SubElement(obj, \"name\")\n",
    "        name.text = class_name\n",
    "\n",
    "        bndbox = ET.SubElement(obj, \"bndbox\")\n",
    "        ET.SubElement(bndbox, \"xmin\").text = str(xmin)\n",
    "        ET.SubElement(bndbox, \"ymin\").text = str(ymin)\n",
    "        ET.SubElement(bndbox, \"xmax\").text = str(xmax)\n",
    "        ET.SubElement(bndbox, \"ymax\").text = str(ymax)\n",
    "\n",
    "    # Save XML inside the main \"xmls/\" directory\n",
    "    xml_filename = os.path.join(output_xml_dir, os.path.splitext(os.path.basename(image_path))[0] + \".xml\")\n",
    "    tree = ET.ElementTree(annotation)\n",
    "    tree.write(xml_filename)\n",
    "\n",
    "# Load class dictionary (Mapping class IDs to Names)\n",
    "class_dict = {\n",
    "    0: \"Baji\", 1: \"Bara\", 2: \"Bhutan\", 3: \"Bhuti\", 4: \"Buffalo Masu(Dakulaa)\",\n",
    "    5: \"Channa\", 6: \"Dhau\", 7: \"Kachilaa\", 8: \"Lain tarkari\", 9: \"Lainachar\",\n",
    "    10: \"Saag\", 11: \"Thoo\", 12: \"aloo\", 13: \"egg\", 14: \"sapumicha\", 15: \"yomari\"\n",
    "}  # Updated with your 16 food classes\n",
    "\n",
    "# Count processed images\n",
    "total_images = 0\n",
    "\n",
    "# Process each image and its corresponding TXT file\n",
    "for img_file in os.listdir(images_dir):\n",
    "    img_ext = os.path.splitext(img_file)[1].lower()\n",
    "    if img_ext in VALID_EXTENSIONS:\n",
    "        image_path = os.path.join(images_dir, img_file)\n",
    "        txt_filename = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        txt_path = os.path.join(txt_dir, txt_filename)\n",
    "\n",
    "        if os.path.exists(txt_path):\n",
    "            create_voc_xml(image_path, txt_path, class_dict, xml_output_dir)\n",
    "            total_images += 1\n",
    "        else:\n",
    "            print(f\"Warning: No TXT annotation found for {img_file}\")\n",
    "\n",
    "print(f\"âœ… Conversion complete! Processed {total_images} images.\")\n",
    "print(\"ðŸ“‚ XML annotations are stored inside 'final_splitted_dataset/xmls/'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1.0\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "print(PIL.__version__)\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.new('RGB', (100, 100), color=(255, 0, 0))\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in train set: 6029\n",
      "Total images in test set: 1516\n",
      "Grand total images in dataset: 7545\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define dataset directories\n",
    "root_dir = \"final_splitted_dataset\"\n",
    "train_dir = os.path.join(root_dir, \"train\")\n",
    "test_dir = os.path.join(root_dir, \"test\")\n",
    "\n",
    "# Supported image extensions\n",
    "VALID_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"}\n",
    "\n",
    "# Function to count images in a directory\n",
    "def count_images(directory):\n",
    "    total_images = 0\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            total_images += len([img for img in os.listdir(class_path) if os.path.splitext(img)[1].lower() in VALID_EXTENSIONS])\n",
    "    return total_images\n",
    "\n",
    "# Count images in train and test folders\n",
    "train_count = count_images(train_dir)\n",
    "test_count = count_images(test_dir)\n",
    "\n",
    "# Print results\n",
    "print(f\"Total images in train set: {train_count}\")\n",
    "print(f\"Total images in test set: {test_count}\")\n",
    "print(f\"Grand total images in dataset: {train_count + test_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
